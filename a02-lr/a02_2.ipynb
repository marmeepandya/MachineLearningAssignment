{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a84051c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib as plt\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from a02_helper import *\n",
    "from a02_functions import sigma, logsigma, l, dl, gd, sgdepoch, sgd, optimize"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "593a502e",
   "metadata": {},
   "source": [
    "# 2. Maximum Likelihood Estimation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a98c2f33",
   "metadata": {},
   "source": [
    "## Helper functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffe3394f",
   "metadata": {},
   "source": [
    "Define the logistic function in `a02_functions.py`. Make sure it operates on both\n",
    "scalars and vectors. Then test it below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a4fc13d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.5, array([0.26894142, 0.5       , 0.73105858])]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this should give:\n",
    "# [0.5, array([0.26894142, 0.5, 0.73105858])]\n",
    "[sigma(0), sigma(np.array([-1, 0, 1]))]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37b5ecb5",
   "metadata": {},
   "source": [
    "Define the logarithm of the logistic function in `a02_functions.py`. Make sure it\n",
    "operates on both scalars and vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "caec6eeb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-0.6931471805599453, array([-1.31326169, -0.69314718, -0.31326169])]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this should give:\n",
    "# [-0.69314718055994529, array([-1.31326169, -0.69314718, -0.31326169])]\n",
    "[logsigma(0), logsigma(np.array([-1, 0, 1]))]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5be99b91",
   "metadata": {},
   "source": [
    "## 2b Log-likelihood and gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00bee81c",
   "metadata": {},
   "source": [
    "Complete the function for the log-likelihood of the logistic regression model in\n",
    "`a02_functions.py` and test it below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "12166e33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this should give:\n",
    "# -47066.641667825766\n",
    "l(y, Xz, np.linspace(-5, 5, D))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b739d598",
   "metadata": {},
   "source": [
    "Now fill out the function that returns the gradient of the log-likelihood of the\n",
    "logistic regression model in `a02_functions.py`, and test it below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb367b5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this should give:\n",
    "# array([  551.33985842,   143.84116318,   841.83373606,   156.87237578,\n",
    "#          802.61217579,   795.96202907,   920.69045803,   621.96516752,\n",
    "#          659.18724769,   470.81259805,   771.32406968,   352.40325626,\n",
    "#          455.66972482,   234.36600888,   562.45454038,   864.83981264,\n",
    "#          787.19723703,   649.48042176,   902.6478154 ,   544.00539886,\n",
    "#         1174.78638035,   120.3598967 ,   839.61141672,   633.30453444,\n",
    "#         -706.66815087,  -630.2039816 ,  -569.3451386 ,  -527.50996698,\n",
    "#         -359.53701083,  -476.64334832,  -411.60620464,  -375.11950586,\n",
    "#         -345.37195689,  -376.22044258,  -407.31761977,  -456.23251936,\n",
    "#         -596.86960184,  -107.97072355,  -394.82170044,  -229.18125598,\n",
    "#         -288.46356547,  -362.13402385,  -450.87896465,  -277.03932676,\n",
    "#         -414.99293368,  -452.28771693,  -167.54649092,  -270.9043748 ,\n",
    "#         -252.20140951,  -357.72497343,  -259.12468742,   418.35938483,\n",
    "#          604.54173228,    43.10390907,   152.24258478,   378.16731033,\n",
    "#          416.12032881])\n",
    "dl(y, Xz, np.linspace(-5, 5, D))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72e3a7a6",
   "metadata": {},
   "source": [
    "## 2c Gradient descent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f75ac39",
   "metadata": {},
   "source": [
    "In `a02_functions.py`, define the objective and update function for one\n",
    "gradient-descent epoch for fitting an MLE estimate of logistic regression with\n",
    "gradient descent (should return a tuple of two functions; see `optimize` in\n",
    "`a02_functions.py`). Then test it below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f510a417",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this should give\n",
    "# [47066.641667825766,\n",
    "#  array([  4.13777838e+01,  -1.56745627e+01,   5.75882538e+01,\n",
    "#           1.14225143e+01,   5.54249703e+01,   5.99229049e+01,\n",
    "#           7.11220141e+01,   4.84761728e+01,   5.78067289e+01,\n",
    "#           4.54794720e+01,   7.14638492e+01,   1.51369386e+01,\n",
    "#           3.36375739e+01,   2.15061217e+01,   5.78014255e+01,\n",
    "#           6.72743066e+01,   7.00829312e+01,   5.29328088e+01,\n",
    "#           6.16042473e+01,   5.50018510e+01,   8.94624817e+01,\n",
    "#           2.74784480e+01,   8.51763599e+01,   5.60363965e+01,\n",
    "#          -2.55865589e+01,  -1.53788213e+01,  -4.67015412e+01,\n",
    "#          -2.50356570e+00,  -3.85357592e+00,  -2.21819155e+00,\n",
    "#           3.32098671e+00,   3.86933390e+00,  -2.00309898e+01,\n",
    "#           3.84684492e+00,  -2.19847927e-01,  -1.29775457e+00,\n",
    "#          -1.28374302e+01,  -2.78303173e+00,  -5.61671182e+00,\n",
    "#           1.73657121e+01,  -6.81197570e+00,  -1.20249002e+01,\n",
    "#           2.65789491e+00,  -1.39557852e+01,  -2.01135653e+01,\n",
    "#          -2.72134051e+01,  -9.45952961e-01,  -1.02239111e+01,\n",
    "#           1.52794293e-04,  -5.18938123e-01,  -3.19717561e+00,\n",
    "#           4.62953437e+01,   7.87893022e+01,   1.88618651e+01,\n",
    "#           2.85195027e+01,   5.04698358e+01,   6.41240689e+01])\n",
    "f, update = gd(y, Xz)\n",
    "[f(np.linspace(-5, 5, D)), update(np.linspace(-5, -5, D), 0.1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cbaeb94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now you can run gradient descent!\n",
    "np.random.seed(0)\n",
    "w0 = np.random.normal(size=D)\n",
    "wz_gd, vz_gd, ez_gd = optimize(gd(y, Xz), w0, nepochs=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f07021f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at how gradient descent made progess\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc78a56e",
   "metadata": {},
   "source": [
    "## 2d Stochastic gradient descent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f8d2478",
   "metadata": {},
   "source": [
    "Implement stochastic gradient descent in `a02_functions.py`. Then test it with the\n",
    "given results below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "768d0c67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# when you run this multiple times, with 50% probability you should get the\n",
    "# following result (there is one other result which is very close):\n",
    "# array([ -3.43689655e+02,  -1.71161311e+02,  -5.71093536e+02,\n",
    "#         -5.16478220e+01,   4.66294348e+02,  -3.71589878e+02,\n",
    "#          5.21493183e+02,   1.25699230e+03,   8.33804130e+02,\n",
    "#          5.63185399e+02,   1.32761302e+03,  -2.64104011e+02,\n",
    "#          7.10693307e+02,  -1.75497331e+02,  -1.94174427e+02,\n",
    "#          1.11641507e+02,  -3.30817509e+02,  -3.46754913e+02,\n",
    "#          8.48722111e+02,  -1.89136304e+02,  -4.25693844e+02,\n",
    "#         -1.23084189e+02,  -2.95894797e+02,  -2.35789333e+02,\n",
    "#         -3.38695243e+02,  -3.05642830e+02,  -2.28975383e+02,\n",
    "#         -2.38075137e+02,  -1.66702530e+02,  -2.27341599e+02,\n",
    "#         -1.77575620e+02,  -1.49093855e+02,  -1.70028859e+02,\n",
    "#         -1.50243833e+02,  -1.82986008e+02,  -2.41143708e+02,\n",
    "#         -3.31047159e+02,  -5.79991185e+01,  -1.98477863e+02,\n",
    "#         -1.91264948e+02,  -1.17371919e+02,  -1.66953779e+02,\n",
    "#         -2.01472565e+02,  -1.23330949e+02,  -3.00857740e+02,\n",
    "#         -1.95853348e+02,  -7.44868073e+01,  -1.11172370e+02,\n",
    "#         -1.57618226e+02,  -1.25729512e+00,  -1.45536466e+02,\n",
    "#         -1.43362438e+02,  -3.00429708e+02,  -9.84391082e+01,\n",
    "#         -4.54152047e+01,  -5.26492232e+01,  -1.45175427e+02])\n",
    "sgdepoch(y[1:3], Xz[1:3, :], np.linspace(-5, 5, D), 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d805a7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with 50% probability, you should get:\n",
    "# [40.864973045695081,\n",
    "#  array([ -3.43689655e+02,  -1.71161311e+02,  -5.71093536e+02,\n",
    "#          -5.16478220e+01,   4.66294348e+02,  -3.71589878e+02,\n",
    "#           5.21493183e+02,   1.25699230e+03,   8.33804130e+02,\n",
    "#           5.63185399e+02,   1.32761302e+03,  -2.64104011e+02,\n",
    "#           7.10693307e+02,  -1.75497331e+02,  -1.94174427e+02,\n",
    "#           1.11641507e+02,  -3.30817509e+02,  -3.46754913e+02,\n",
    "#           8.48722111e+02,  -1.89136304e+02,  -4.25693844e+02,\n",
    "#          -1.23084189e+02,  -2.95894797e+02,  -2.35789333e+02,\n",
    "#          -3.38695243e+02,  -3.05642830e+02,  -2.28975383e+02,\n",
    "#          -2.38075137e+02,  -1.66702530e+02,  -2.27341599e+02,\n",
    "#          -1.77575620e+02,  -1.49093855e+02,  -1.70028859e+02,\n",
    "#          -1.50243833e+02,  -1.82986008e+02,  -2.41143708e+02,\n",
    "#          -3.31047159e+02,  -5.79991185e+01,  -1.98477863e+02,\n",
    "#          -1.91264948e+02,  -1.17371919e+02,  -1.66953779e+02,\n",
    "#          -2.01472565e+02,  -1.23330949e+02,  -3.00857740e+02,\n",
    "#          -1.95853348e+02,  -7.44868073e+01,  -1.11172370e+02,\n",
    "#          -1.57618226e+02,  -1.25729512e+00,  -1.45536466e+02,\n",
    "#          -1.43362438e+02,  -3.00429708e+02,  -9.84391082e+01,\n",
    "#          -4.54152047e+01,  -5.26492232e+01,  -1.45175427e+02])]\n",
    "f, update = sgd(y[1:3], Xz[1:3, :])\n",
    "[f(np.linspace(-5, 5, D)), update(np.linspace(-5, 5, D), 1000)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b08a06be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# you can run stochastic gradient descent!\n",
    "wz_sgd, vz_sgd, ez_sgd = optimize(sgd(y, Xz), w0, nepochs=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aa054f9",
   "metadata": {},
   "source": [
    "## 2e Compare GD and SGD"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cedba197",
   "metadata": {},
   "source": [
    "Explore the behavior of both methods, given the parameters provided to you!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ac0f931",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "main_language": "python"
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
